# æ”¯æŒå›¾ç‰‡ç†è§£
# -*- coding: utf-8 -*-
# å¯¼å…¥æ‰€éœ€åº“
import gradio as gr
from openai import OpenAI
import base64
import webbrowser

# -------------------- å®¢æˆ·ç«¯åˆå§‹åŒ– --------------------
# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼ˆé€‚é…é˜¿é‡Œäº‘å¹³å°ï¼‰
client = OpenAI(
    api_key="your_key",  # è¾“å…¥APIå¯†é’¥
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",  # é˜¿é‡Œäº‘å…¼å®¹æ¥å£
)


# -------------------- å…¨å±€é…ç½® --------------------
MODEL_CONFIG = {
    "available_models": [
        "deepseek-r1",
        "deepseek-v3",
        "qwen-omni-turbo-latest",
        "llama3.3-70b-instruct"
    ],
    "default_model": "deepseek-r1",
    "max_history": 8
}

# -------------------- ç³»ç»Ÿæ ¸å¿ƒåŠŸèƒ½ --------------------
class ChatSystem:
    def __init__(self):
        self.history = []
        self.chat_records = []
        self.stop_flag = False  # æ–°å¢åœæ­¢æ ‡å¿—

# ç”¨äºå¤„ç†å›¾ç‰‡ï¼Œè°ƒç”¨qwen-vl-plusæ¨¡å‹
    def _process_image(self, image_path):
        try:
            with open(image_path, "rb") as f:
                base64_data = base64.b64encode(f.read()).decode("utf-8")
            
            response = client.chat.completions.create(
                model="qwen-vl-plus",
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "è¯¦ç»†æè¿°å›¾ç‰‡å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»è¦ç‰©ä½“ã€åœºæ™¯ç‰¹å¾ã€æ–‡å­—ä¿¡æ¯ç­‰"},
                        {"type": "image_url", "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_data}"
                        }}
                    ]
                }]
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"âš ï¸ å›¾ç‰‡è§£æå¤±è´¥ï¼š{str(e)}"

    def stop_generation(self):  # åœæ­¢æ–¹æ³•
        self.stop_flag = True

    def generate_response(self, user_input, selected_model, image_path=None):
        self.stop_flag = False  # æ¯æ¬¡ç”Ÿæˆå‰é‡ç½®æ ‡å¿—
        
        # å¤„ç†å›¾ç‰‡å¹¶åˆå¹¶åˆ°ç”¨æˆ·è¾“å…¥
        combined_input = user_input
        if image_path:
            analysis_result = self._process_image(image_path)
            combined_input = f"{user_input}\n[å›¾ç‰‡åˆ†æ]: {analysis_result}"
        
        # è®°å½•ç”¨æˆ·è¾“å…¥ï¼ˆä»…æ˜¾ç¤ºåŸå§‹å†…å®¹ï¼‰
        user_entry = f'<div class="user-message">{user_input}</div>'
        self.chat_records.append(user_entry)
        
        # å®é™…å‘é€åˆå¹¶åçš„å†…å®¹
        self.history.append({"role": "user", "content": combined_input})
        context = self.history[-MODEL_CONFIG["max_history"]*2:]
        
        full_response = ""
        reasoning_content = ""
        try:
            stream = client.chat.completions.create(
                model=selected_model,
                messages=context,
                stream=True,
                temperature=0.7
            )
            
            for chunk in stream:
                if self.stop_flag:  # æ£€æŸ¥åœæ­¢æ ‡å¿—
                    full_response += "<br>ï¼ˆå›ç­”å·²ä¸­æ–­ï¼‰"
                    break
                
                delta = chunk.choices[0].delta
                
                if hasattr(delta, "reasoning_content") and delta.reasoning_content:
                    reasoning_content += delta.reasoning_content
                
                if hasattr(delta, "content") and delta.content:
                    full_response += delta.content
                
                current_display = "<div class='chat-container'>" + "\n".join(self.chat_records) + \
                    f'<div class="assistant-message"><div class="response">{full_response}</div>' + \
                    (f'<div class="reasoning">{reasoning_content}</div>' if reasoning_content else "") + "</div></div>"
                yield current_display
            
            self.history.append({"role": "assistant", "content": full_response})
            self.chat_records.append(
                f'<div class="assistant-message"><div class="response">{full_response}</div>' + \
                (f'<div class="reasoning">{reasoning_content}</div>' if reasoning_content else "") + "</div>"
            )
        except Exception as e:
            error_msg = f'<div class="error-message">ğŸ”´ ç³»ç»Ÿé”™è¯¯ï¼š{str(e)}</div>'
            self.chat_records.append(error_msg)
            yield "<div class='chat-container'>" + "\n".join(self.chat_records) + "</div>"

    def clear_history(self):
        self.history = []
        self.chat_records = []
        return "<div style='color:#7f8c8d; text-align: center;'>âœ… å¯¹è¯å†å²å·²é‡ç½®</div>"

# -------------------- ç•Œé¢å®ç° --------------------
class ChatInterface:
    def __init__(self, system):
        self.system = system
        self.demo = self._create_interface()
    
    def _create_interface(self):
        custom_css = """
        #chat-box { 
            height: 55vh !important;
            overflow-y: auto !important;
            border: 1px solid #e0e0e0;
            padding: 15px;
            border-radius: 10px;
            background: #f9f9f9;
        }
        .chat-container {
            display: flex;
            flex-direction: column;
            gap: 10px;
        }
        .user-message {
            align-self: flex-end;
            background: #e3f2fd;
            padding: 10px 15px;
            border-radius: 15px;
            max-width: 70%;
            word-break: break-word;
            margin-left: 30%;
        }
        .assistant-message {
            align-self: flex-start;
            background: #f5f5f5;
            padding: 10px 15px;
            border-radius: 15px;
            max-width: 70%;
            word-break: break-word;
            margin-right: 30%;
        }
        .reasoning {
            color: #7f8c8d;
            font-size: 0.9em;
            margin-top: 8px;
            padding-top: 8px;
            border-top: 1px dashed #ddd;
        }
        .error-message {
            color: #e74c3c;
            padding: 10px;
            text-align: center;
        }
        .input-section {
            padding: 12px;
            background: #ffffff;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        /* æ–°å¢æŒ‰é’®é«˜åº¦æ ·å¼ */
        #submit-btn {
            height: 70px !important;  /* è®¾ç½®æŒ‰é’®é«˜åº¦ä¸º60px */
        }
        """

        with gr.Blocks(theme=gr.themes.Soft(), css=custom_css, title="å¤šæ¨¡æ€AIåŠ©æ‰‹") as interface:
            gr.Markdown("""<h1 style="text-align: center; color: #2c3e50;">ğŸŒˆ å¤šæ¨¡æ€AIåŠ©æ‰‹</h1>
            <p style="text-align: center; color: #7f8c8d;">æ”¯æŒå›¾ç‰‡ç†è§£ | å¤šæ¨¡å‹åˆ‡æ¢ | ä¸Šä¸‹æ–‡è®°å¿†</p>
            <hr style="margin-bottom: 20px;">""")
            
            with gr.Row():
                with gr.Column(scale=3):
                    chat_display = gr.HTML(
                        elem_id="chat-box",
                        value="<div style='color:#7f8c8d; text-align: center;'>æ¬¢è¿ä½¿ç”¨æ™ºèƒ½åŠ©æ‰‹ï¼</div>"
                    )
                
                with gr.Column(scale=1):
                    with gr.Accordion("ğŸ“· å›¾åƒå¤„ç†åŒº", open=True):
                        image_upload = gr.Image(
                            label="ä¸Šä¼ å›¾ç‰‡",
                            type="filepath",
                            height=140,
                            interactive=True
                        )
                    
                    with gr.Accordion("âš™ï¸ æ¨¡å‹æ§åˆ¶", open=True):
                        model_selector = gr.Dropdown(
                            label="é€‰æ‹©AIæ¨¡å‹",
                            choices=MODEL_CONFIG["available_models"],
                            value=MODEL_CONFIG["default_model"],
                            interactive=True
                        )
                        with gr.Row():
                            clear_btn = gr.Button("ğŸ”„ æ–°å¯¹è¯", variant="secondary")
                            stop_btn = gr.Button("â¹ï¸ åœæ­¢ç”Ÿæˆ", variant="stop")
            
            with gr.Row(variant="panel"):
                with gr.Column(scale=3):
                    user_input = gr.Textbox(
                        placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
                        lines=2,
                        max_lines=4,
                        show_label=False
                    )
                with gr.Column(scale=1):
                    submit_btn = gr.Button("ğŸš€ å‘é€", variant="primary", elem_id="submit-btn")
            
            submit_event = submit_btn.click(
                self.system.generate_response,
                [user_input, model_selector, image_upload],
                chat_display
            ).then(
                lambda: [None, ""],
                outputs=[image_upload, user_input]
            )
            
            user_input.submit(
                self.system.generate_response,
                [user_input, model_selector, image_upload],
                chat_display
            ).then(
                lambda: [None, ""],
                outputs=[image_upload, user_input]
            )
            
            clear_btn.click(
                self.system.clear_history,
                outputs=chat_display
            )
            
            stop_btn.click(
                lambda: self.system.stop_generation(),
                inputs=None,
                outputs=None,
            )
        
        return interface

# -------------------- å¯åŠ¨ç³»ç»Ÿ --------------------
if __name__ == "__main__":
    chat_system = ChatSystem()
    interface = ChatInterface(chat_system)
    webbrowser.open("http://127.0.0.1:7860")
    interface.demo.launch(
        server_name="127.0.0.1",
        server_port=7860,
        show_error=True
    )