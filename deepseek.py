# -*- coding: utf-8 -*-
# å¯¼å…¥æ‰€éœ€åº“
import gradio as gr
from openai import OpenAI
import webbrowser  # å¯¼å…¥webbrowseræ¨¡å—ç”¨äºè‡ªåŠ¨æ‰“å¼€é“¾æ¥

# -------------------- å®¢æˆ·ç«¯åˆå§‹åŒ– --------------------
# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼ˆé€‚é…é˜¿é‡Œäº‘å¹³å°ï¼‰
client = OpenAI(
    api_key="your_key",  # è¾“å…¥APIå¯†é’¥
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",  # é˜¿é‡Œäº‘å…¼å®¹æ¥å£
)


# -------------------- # æ¨¡å‹é…ç½® --------------------
AVAILABLE_MODELS = [
    "deepseek-r1",
    "deepseek-v3",
    "qwen-omni-turbo-latest",
    "llama3.3-70b-instruct"
]
HISTORY_ROUNDS = 10  # é»˜è®¤ä¿ç•™10è½®

# åˆå§‹åŒ–æ¶ˆæ¯å†å²è®°å½•
messages_history = []


# -------------------- æ ¸å¿ƒèŠå¤©å‡½æ•° --------------------
def chat_with_model(user_input, chat_output, selected_model):
    """
    ä¸DeepSeekæ¨¡å‹è¿›è¡Œäº¤äº’çš„æ ¸å¿ƒå‡½æ•°

    å‚æ•°ï¼š
    user_input (str): ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
    chat_output (str): å½“å‰èŠå¤©è¾“å‡ºå†…å®¹
    selected_model (str): é€‰æ‹©çš„æ¨¡å‹åç§°

    è¿”å›ï¼š
    generator: é€šè¿‡yieldé€æ­¥è¿”å›ç”Ÿæˆçš„èŠå¤©å†…å®¹
    """
    # å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°æ¶ˆæ¯å†å²è®°å½•
    messages_history.append({'role': 'user', 'content': user_input})

    recent_messages = messages_history[-HISTORY_ROUNDS*2:]  # æ¯è½®åŒ…å«userå’Œassistantä¸¤æ¡

    # åˆå§‹åŒ–æ€è€ƒè¿‡ç¨‹å’Œå›ç­”å†…å®¹
    reasoning_content = ""  # å­˜å‚¨æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹
    answer_content = ""  # å­˜å‚¨æœ€ç»ˆå›ç­”

    # æ ¼å¼åŒ–è¾“å‡ºå†…å®¹
    chat_output += f"\n\n"
    chat_output += f"  \n**è¾“å…¥:** {user_input}\n"  # æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    chat_output += f"  \n<span style='color: gray;'>**æ€è€ƒè¿‡ç¨‹:** </span> \n"  # ç°è‰²æ€è€ƒè¿‡ç¨‹æ ‡é¢˜

    # è°ƒç”¨é˜¿é‡Œäº‘APIè¿›è¡Œæµå¼å“åº”
    completion = client.chat.completions.create(
        model=selected_model,  # ä½¿ç”¨é€‰æ‹©çš„æ¨¡å‹
        messages=recent_messages,  # ä¼ å…¥æœ€è¿‘å¯¹è¯ä¸Šä¸‹æ–‡
        stream=True  # å¯ç”¨æµå¼ä¼ è¾“
    )

    begin_answer = 0  # å›ç­”éƒ¨åˆ†å¼€å§‹æ ‡è®°
    for chunk in completion:
        delta = chunk.choices[0].delta

        # è·å–æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹å†…å®¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if hasattr(delta, "reasoning_content") and delta.reasoning_content:
            reasoning_chunk = delta.reasoning_content
            reasoning_content += reasoning_chunk
            # ç”¨ç°è‰²æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
            chat_output += f"<span style='color: gray;'>{reasoning_chunk}</span>"

        # è·å–æ¨¡å‹çš„å›ç­”å†…å®¹
        if hasattr(delta, "content") and delta.content:
            if begin_answer == 0:  # é¦–æ¬¡å‡ºç°å›ç­”æ—¶æ·»åŠ æ ‡é¢˜
                chat_output += f"  \n**å›ç­”:** \n"
                begin_answer = 1
            answer_chunk = delta.content
            answer_content += answer_chunk
            chat_output += answer_chunk  # ç›´æ¥æ˜¾ç¤ºå›ç­”å†…å®¹

        yield chat_output  # é€æ­¥è¿”å›ç”Ÿæˆå†…å®¹

    # å°†åŠ©æ‰‹çš„æœ€ç»ˆå›ç­”æ·»åŠ åˆ°æ¶ˆæ¯å†å²è®°å½•
    messages_history.append({'role': 'assistant', 'content': answer_content})


# -------------------- æ¸…ç©ºå¯¹è¯å‡½æ•° --------------------
def clear_conversation(chat_output):
    """
    æ¸…ç©ºå¯¹è¯å†å²å’ŒèŠå¤©ç•Œé¢

    å‚æ•°ï¼š
    chat_output (str): å½“å‰èŠå¤©è¾“å‡ºå†…å®¹

    è¿”å›ï¼š
    str: æ¸…ç©ºåçš„ç©ºå­—ç¬¦ä¸²
    """
    global messages_history
    messages_history = []  # é‡ç½®æ¶ˆæ¯å†å²
    chat_output = ""  # æ¸…ç©ºèŠå¤©æ˜¾ç¤º
    return chat_output


# -------------------- Gradioç•Œé¢æ„å»º --------------------
with gr.Blocks() as demo:  # åˆ›å»ºå—çŠ¶å¸ƒå±€ç•Œé¢
    gr.Markdown("""<h1 style="text-align: center; color: #2c3e50;">ğŸŒˆ deepseekâ€”â€”AIåŠ©æ‰‹</h1>""")  # æ›´æ–°æ ‡é¢˜

    # æ¨¡å‹é€‰æ‹©åŒºåŸŸ
    with gr.Row():
        model_selector = gr.Dropdown(
            label="é€‰æ‹©æ¨¡å‹",
            choices=AVAILABLE_MODELS,
            value=AVAILABLE_MODELS[0],
            interactive=True
        )

    # èŠå¤©æ˜¾ç¤ºåŒºåŸŸ
    with gr.Row():
        with gr.Column():
            chat_output = gr.Markdown(label="Chat", value="")

    # è¾“å…¥æ§åˆ¶åŒºåŸŸ
    with gr.Row():
        with gr.Column():
            user_input = gr.Textbox(
                label="è¾“å…¥",
                placeholder="Type your message here...",
                lines=2
            )
            with gr.Row():
                submit_button = gr.Button("Submit")  # æäº¤æŒ‰é’®
                clear_button = gr.Button("å¼€å§‹æ–°å¯¹è¯")  # æ¸…ç©ºæŒ‰é’®

    # ç»‘å®šæŒ‰é’®äº‹ä»¶
    submit_button.click(
        fn=chat_with_model,  # è§¦å‘èŠå¤©å‡½æ•°
        inputs=[user_input, chat_output, model_selector],  # æ–°å¢æ¨¡å‹é€‰æ‹©è¾“å…¥
        outputs=chat_output  # è¾“å‡ºç›®æ ‡
    )

    clear_button.click(
        fn=clear_conversation,  # è§¦å‘æ¸…ç©ºå‡½æ•°
        inputs=[chat_output],  # è¾“å…¥å‚æ•°
        outputs=chat_output  # è¾“å‡ºç›®æ ‡
    )

# -------------------- å¯åŠ¨åº”ç”¨ --------------------
# å¯åŠ¨Gradioåº”ç”¨å¹¶è‡ªåŠ¨æ‰“å¼€é“¾æ¥
webbrowser.open("http://127.0.0.1:7860")
demo.launch(server_name="127.0.0.1", server_port=7860, show_api=False)